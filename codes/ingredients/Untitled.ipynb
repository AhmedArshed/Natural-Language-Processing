{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ingrident_df = pd.read_json('xyz.json')\n",
    "ingrident_df.dropna(axis=1 ,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingrident_list = []\n",
    "orignal_ingrident =[]\n",
    "title_list = []\n",
    "id_list = []\n",
    "for i in ingrident_df:\n",
    "    ingrident_list.append(ingrident_df[i]['ingredients'])\n",
    "    orignal_ingrident.append(ingrident_df[i]['ingredients'])\n",
    "    title_list.append(ingrident_df[i]['title'])\n",
    "    id_list.append(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3053"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ingredient = pd.read_json('test.json')\n",
    "all_gred = []\n",
    "all_gred.append('onion')\n",
    "for i in get_ingredient['ingredients']:\n",
    "    for j in i:\n",
    "        if j not in all_gred:\n",
    "            splt = j.split(' ')\n",
    "            if len(splt) <= 2:\n",
    "                all_gred.append(j)\n",
    "len(all_gred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4567"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ingredient = pd.read_json('train.json')\n",
    "for i in train_ingredient['ingredients']:\n",
    "    for j in i:\n",
    "        if j not in all_gred:\n",
    "            splt = j.split(' ')\n",
    "            if len(splt) <= 2:\n",
    "                all_gred.append(j)\n",
    "len(all_gred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "print(\"Done\")\n",
    "from nltk.corpus import wordnet as wn\n",
    "words = ['minced', 'garlic','boneless','all-purpose' ,'flour']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UniqueGradient(gradient):\n",
    "    n_gradient = []\n",
    "    for i in range(len(gradient)):\n",
    "    #print(gradient[i])\n",
    "        flag = True\n",
    "        for j in range(len(gradient)):\n",
    "            if len(gradient[i]) < len(gradient[j])  and gradient[i] in gradient[j]:\n",
    "                flag = False\n",
    "        if flag:\n",
    "            n_gradient.append(gradient[i])\n",
    "    return n_gradient\n",
    "def stem(a):\n",
    "    p = nltk.PorterStemmer()\n",
    "    [p.stem(word) for word in a]\n",
    "    return a\n",
    "import inflect\n",
    "def OnlyNoun(words):\n",
    "    lst = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            p = inflect.engine()\n",
    "            word = p.plural(w)\n",
    "            word = stem(word)\n",
    "            tmp = wn.synsets(w)[0].pos()\n",
    "        except:\n",
    "            tmp = 'n'\n",
    "        if tmp == 'n' and w not in ['ground','baby','cold','breast','extract','sweet']:\n",
    "            lst.append(w)\n",
    "    return ' '.join(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_gradients = []\n",
    "for k in range(len(ingrident_list)):\n",
    "    gradient = []\n",
    "    ingridentString = ' '.join(ingrident_list[k])\n",
    "    #print(ingridentString)\n",
    "    for i in all_gred:\n",
    "        if (i+' ' in ingridentString or i+',' in ingridentString)  and i not in gradient:\n",
    "            if ' ' in i:\n",
    "                a = OnlyNoun(i.split(' '))\n",
    "            else:\n",
    "                a = OnlyNoun([i])\n",
    "            if a not in gradient:\n",
    "                gradient.append(a)\n",
    "    main_gradients.append(UniqueGradient(gradient))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 cup butter, melted ADVERTISEMENT 2 eggs, beaten ADVERTISEMENT 1 (8.5 ounce) package dry corn bread mix ADVERTISEMENT 1 (15 ounce) can whole kernel corn, drained ADVERTISEMENT 1 (14.75 ounce) can creamed corn ADVERTISEMENT 1 cup sour cream ADVERTISEMENT ADVERTISEMENT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Awesome and Easy Creamy Corn Casserole',\n",
       " ['eggs', 'butter', 'sour cream', 'bread mix', 'corn bread'],\n",
       " ['1/2 cup butter, melted ADVERTISEMENT',\n",
       "  '2 eggs, beaten ADVERTISEMENT',\n",
       "  '1 (8.5 ounce) package dry corn bread mix ADVERTISEMENT',\n",
       "  '1 (15 ounce) can whole kernel corn, drained ADVERTISEMENT',\n",
       "  '1 (14.75 ounce) can creamed corn ADVERTISEMENT',\n",
       "  '1 cup sour cream ADVERTISEMENT',\n",
       "  'ADVERTISEMENT'],\n",
       " 'QVPNMtrpqZDbM5K6hYfMTb2Ez4.jlfa')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "ingridentString = ' '.join(ingrident_list[100])\n",
    "print(ingridentString)\n",
    "dic = {}\n",
    "for i in range(len(main_gradients)):\n",
    "    dic[i] =title_list[i] , main_gradients[i] ,orignal_ingrident[i], id_list[i]\n",
    "dic[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dic,index=['tilte', 'ingredients','orignal ingrident','id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_json('final_output.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
